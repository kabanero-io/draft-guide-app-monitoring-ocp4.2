---
permalink: /guides/ocp-app-monitoring/
---
:projectid: ocp-app-monitoring
:page-layout: guide-multipane
:page-duration: 60 minutes
:page-releasedate: 2020-01-10
:page-guide-category: basic
:page-description: Learn how to monitor applications on OCP 4.2 with Prometheus and Grafana.
:page-tags: ['monitoring', 'prometheus', 'grafana']
= Application Monitoring on OCP 4.2 with Prometheus and Grafana

== Introduction

__The following guide has been tested with OCP 4.2/Kabanero 0.3.0.__


For application monitoring on OCP (OpenShift Container Platform), you need to set up your own Prometheus and Grafana deployments. Prometheus can be set up via Prometheus Operator on OCP. 

=== Deploy an Application with MP Metrics Endpoint
Prior to deploying Prometheus, ensure that there is a running application that has a service endpoint for outputting metrics in Prometheus format. 

It is assumed such a running application has been deployed to the OCP cluster inside a project/namespace called `myapp`, and that the Prometheus metrics endpoint is exposed on path `/metrics`.

== Deploy Prometheus - Prometheus Operator

service_monitor.yaml
[source, yaml, linenums, role='code-column']
----
include::code/service_monitor.yaml[]
----

prometheus.yaml
[source, yaml, linenums, role='code-column']
----
include::code/prometheus.yaml[]
----

cluster_role.yaml
[source, yaml, linenums, role='code-column']
----
include::code/cluster_role.yaml[]
----

cluster_role_binding.yaml
[source, yaml, linenums, role='code-column']
----
include::code/cluster_role_binding.yaml[]
----

prometheus_snippet.yaml
[source, yaml, linenums, role='code-column']
----
include::code/prometheus_snippet.yaml[]
----

The Prometheus Operator is an open-source project originating from CoreOS and exists as a part of their Kubernetes Operator framework. The Kubernetes Operator framework is the preferred way to deploy Prometheus on a Kubernetes system. When the Prometheus Operator is installed on the Kubernetes system, you no longer need to hand-configure the Prometheus configuration. Instead, you create CoreOS ServiceMonitor resources for each of the service endpoints that needs to be monitored: this makes daily maintainenance of the Prometheus server a lot easier. An architecture overview of the Prometheus Operator is shown below:

image::/img/guide/prometheusOperator.png[link="/img/guide/prometheusOperator.png" alt="Prometheus Operator"]

There are two ways to install the Prometheus Operator:

* **<<option-a-prometheus-operator-installation-through-operator-lifecycle-manager-olm-ocp-4-2,Option A:>>** Option A: Install Prometheus Operator Using Operator Lifecycle Manager (OLM). 
* **<<option-b-prometheus-operator-installation-through-prometheus-operator-git-repository,Option B:>>** Option B: Install Prometheus operator using https://github.com/coreos/prometheus-operator[Prometheus Operator git repository]. 

Using OLM, Prometheus operator can be easily pulled and configured with given templates in OCP Web Console. Installation using git repository will involve more Command line work.

=== Option A: Install Prometheus Operator Using Operator Lifecycle Manager (OLM)

The following procedure is based on https://medium.com/faun/using-the-operator-lifecycle-manager-to-deploy-prometheus-on-openshift-cd2f3abb3511[Using the Operator Lifecycle Manager to deploy Prometheus on Openshift], with the added inclusion of OpenShift commands needed to complete each step.

. Create a new namespace for our Prometheus Operator deployment
+
[role="command"]
----
oc new-project <your-monitoring-namespace>
----
+
. Go to OpenShift Container Platform web console and Click on Operators > OperatorHub. Using the OLM, Operators can be easily pulled, installed and subscribed on the cluster. Ensure that the Project is set to <your-monitoring-namespace>. Search for Prometheus Operator and install it. Choose <your-monitoring-namespace> for a specific namespace on the cluster and subscribe.

. Click on Overview and create a service monitor instance. A ServiceMonitor defines a service endpoint that needs to be monitored by the Prometheus instance.

. Inside the prometheus.yaml file, make sure *metadata.namespace* is <your-monitoring-namespace>. Labels should be configured to match your app deployment's label. For example, inside [hotspot file=0]`service_monitor.yaml` file, an application with label *app: myapp* from namespace **myapp** will be monitored by the service monitor. If the metrics endpoint is secured, you can define a secured endpoint with authentication configuration by following the https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint[endpoint] API documentation of Prometheus Operator.
+
[role="code_command hotspot file=0", subs="quotes"]
----
Refer to the `service_monitor.yaml` file
----
+

. Click on Overview and create a Prometheus instance. A Prometheus resource can scrape the targets defined in the ServiceMonitor resource.

. Inside the YAML file, make sure *metadata.namespace* is <your-monitoring-namespace>. You can define the match expression to select which Service Monitors you are interested in under *spec.serviceMonitorSelector.matchExpressions* as in [hotspot file=1]`prometheus.yaml` file.
+
[role="code_command hotspot file=1", subs="quotes"]
----
Refer to the `prometheus.yaml` file
----
+
. Verify that the Prometheus services have successfully started. 
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc get svc -n <your-monitoring-namespace>
NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
prometheus-operated   ClusterIP   None             <none>        9090/TCP         19h
----
+
. Check the server logs from one of the target pods to see if the services are running properly.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc get pods -n <your-monitoring-namespace>
NAME                                   READY     STATUS    RESTARTS   AGE
prometheus-operator-7fccbd7c74-48m6v   1/1       Running   0          19h
prometheus-prometheus-0                3/3       Running   1          19h
prometheus-prometheus-1                3/3       Running   1          19h
[root@rhel7-ocp]# oc logs prometheus-prometheus-0 -c prometheus -n prometheus-operator
----
+
If you are getting error logs such as below, it is because your service account doesn't have the permission to get the nodes or pods at the cluster scope.
+
[source,role="no_copy"]
----
...
level=error ts=2019-12-13T16:03:29.346678841Z caller=klog.go:94 component=k8s_client_runtime func=ErrorDepth msg="/app/discovery/kubernetes/kubernetes.go:300: Failed to list *v1.Endpoints: endpoints is forbidden: User \"system:serviceaccount:prometheus-operator:prometheus-k8s\" cannot list resource \"endpoints\" in API group \"\" at the cluster scope"
----
Then you should create Cluster role and Cluster role binding.
+
[role="code_command hotspot file=2", subs="quotes"]
----
Refer to `cluster_role.yaml` and `cluster_role_binding.yaml`
----
+
[role="command"]
----
oc apply -f cluster_role.yaml
oc apply -f cluster_role_binding.yaml
----
+
Check the logs again to check if the servers are running properly.

. Expose the prometheus-operated service to use the Prometheus console externally.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc expose svc/prometheus-operated -n <your-monitoring-namespace>
route.route.openshift.io/prometheus-operated exposed
[root@rhel7-ocp]# oc get route -n <your-monitoring-namespace>
NAME         HOST/PORT                                                 PATH      SERVICES     PORT      TERMINATION   WILDCARD
prometheus   prometheus-prometheus-operator.apps.9.37.135.153.nip.io             prometheus   web                     None
----
+
. Visit the prometheus route and go to the Prometheus targets page. 
Check to see that the Prometheus targets page is picking up the target endpoints. If the service endpoint is discovered, but Prometheus is reporting a DOWN status, you need to make the prometheus-operator project globally accessible.
+
[role="command"]
----
oc adm pod-network make-projects-global <your-monitoring-namespace>
----
+


=== Option B: Install Prometheus Operator Using Prometheus Operator Git Repository

The following procedure is based on the https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md[Prometheus Getting Started] guide maintained by the CoreOS team, with the added inclusion of OpenShift commands needed to complete each step.   


. Clone the Prometheus Operator repository
+
[role="command"]
----
git clone https://github.com/coreos/prometheus-operator
----
+
. Create a new namespace for our Prometheus Operator deployment.
+
[role="command"]
----
oc new-project prometheus-operator
----
+
. Open the `bundle.yaml` file and change all instances of **namespace: default** to the the newly created namespace **namespace: prometheus-operator**
+
. Add the line `- --deny-namespaces=openshift-monitoring` to the existing containers *args* section of Prometheus Operator's Deployment definition in the `bundle.yaml` file.
The *--deny-namespaces* argument allows the exclusion of certain namespaces watched by the Prometheus Operator. By default, Prometheus Operator oversees Prometheus deployments across all namespaces. This could be problematic if there are multiple Prometheus Operator deployments on the OCP cluster. For instance, the OCP's Cluster Monitoring feature also deploys a Prometheus Operator in namespace *openshift-monitoring*.  Therefore, *openshift-monitoring* namespace should be excluded by our Prometheus Operator to prevent undesired behaviors.

. Save the `bundle.yaml` file and deploy the Prometheus Operator using the following command. 
+
[role="command"]
----
oc apply -f bundle.yaml
----
+
You may receive an error message like the one below when running the command.
+
[source,role="no_copy"]
----
Error creating: pods "prometheus-operator-5b8bfd696-" is forbidden: unable to validate against any security context constraint: [spec.containers[0].securityContext.securityContext.runAsUser: Invalid value: 65534: must be in the ranges: [1000070000, 1000079999]]
----
+
To correct the error, change the **runAsUser: 65534** field in the `bundle.yaml` file to a valid value that is in the range specified in the error message. In this case, setting **runAsUser: 1000070000** in the `bundle.yaml` would be in the valid range. Save the `bundle.yaml` file and re-deploy the Prometheus Operator.
+
[role="command"]
----
oc delete -f bundle.yaml
oc apply -f bundle.yaml
----
+
The [hotspot file=0]`service_monitor.yaml` file defines a ServiceMonitor resource. A ServiceMonitor defines a service endpoint that needs to be monitored by the Prometheus instance. Take for example, an application with label **app: myapp** from namespace **myapp**, and metrics endpoints defined in **spec.endpoints** to be monitored by the Promtheus Operator. If the metrics endpoint is secured, you can define a secured endpoint with authentication configuration by following the https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint[endpoint] API documentation of Prometheus Operator.
+
[role="code_command hotspot file=0", subs="quotes"]
----
Create the `service_monitor.yaml` file
----
+
. Apply the `service_monitor.yaml` file to create the ServiceMonitor resource.
+
[role="command"]
----
oc apply -f service_monitor.yaml
----
+
. Define a Prometheus resource that can scrape the targets defined in the ServiceMonitor resource. 
Create a [hotspot file=1]`prometheus.yaml` file that aggregates all the files from the git repository directory `prometheus-operator/example/rbac/prometheus/`. NOTE: Make sure to change the `namespace: default` to `namespace: prometheus-operator`.
+
[role="code_command hotspot file=1", subs="quotes"]
----
Create the `prometheus.yaml` file
----
+
. Apply the `prometheus.yaml` file to deploy the Prometheus service. After all the resources are created, apply the Prometheus Operator `bundle.yaml` file again.
+
[role="command"]
----
oc apply -f prometheus.yaml
oc apply -f bundle.yaml
----
+
. Verify that the Prometheus services have successfully started. The prometheus-operated service is created automatically by the prometheus-operator, and is used for registering all deployed Prometheus instances. 
+
[source,role="no_copy"]
----
oc get svc -n prometheus-operator
NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
prometheus            NodePort    172.30.112.199   <none>        9090:30342/TCP   19h
prometheus-operated   ClusterIP   None             <none>        9090/TCP         19h
prometheus-operator   ClusterIP   None             <none>        8080/TCP         21h
----
+
+
. Check the server logs from one of the target pods to see if the services are running properly.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc get pods -n <your-monitoring-namespace>
NAME                                   READY     STATUS    RESTARTS   AGE
prometheus-operator-7fccbd7c74-48m6v   1/1       Running   0          19h
prometheus-prometheus-0                3/3       Running   1          19h
prometheus-prometheus-1                3/3       Running   1          19h
[root@rhel7-ocp]# oc logs prometheus-prometheus-0 -c prometheus -n prometheus-operator
----
+
If you are getting error logs such as below, it is because your service account doesn't have the permission to get the nodes or pods at the cluster scope.
+
[source,role="no_copy"]
----
...
level=error ts=2019-12-13T16:03:29.346678841Z caller=klog.go:94 component=k8s_client_runtime func=ErrorDepth msg="/app/discovery/kubernetes/kubernetes.go:300: Failed to list *v1.Endpoints: endpoints is forbidden: User \"system:serviceaccount:prometheus-operator:prometheus-k8s\" cannot list resource \"endpoints\" in API group \"\" at the cluster scope"
----
Then you should create Cluster role and Cluster role binding.
+
[role="code_command hotspot file=2", subs="quotes"]
----
Refer to `cluster_role.yaml` and `cluster_role_binding.yaml`
----
+
[role="command"]
----
oc apply -f cluster_role.yaml
oc apply -f cluster_role_binding.yaml
----
+
Check the logs again to check if the servers are running properly.

. Expose the prometheus-operated service to use the Prometheus console externally.
+
[source,role="no_copy"]
----
[root@rhel7-ocp]# oc expose svc/prometheus-operated -n prometheus-operator
[root@rhel7-ocp]# oc get route -n prometheus-operator
NAME         HOST/PORT                                                 PATH      SERVICES     PORT      TERMINATION   WILDCARD
prometheus   prometheus-prometheus-operator.apps.9.37.135.153.nip.io             prometheus   web                     None
----
+
. Visit the *prometheus* route and go to the Prometheus *targets* page. 

. If the page is empty with no endpoints, prometheus.yaml file will have to be updated. The ServiceMonitor needs to satisfy both *serviceMonitorNamespaceSelector* and *serviceMonitorSelector* fields before it can be picked up by the Prometheus service. Targets will not be picked up when the target namespace is not the same as prometheus' namespace and is missing the required label. For example, inside [hotspot file=1]`prometheus.yaml` file, only the target namespaces with the label *prometheus: monitoring* will be picked up. 
+
[role="code_command hotspot file=4", subs="quotes"]
----
Update `prometheus.yaml` to reflect the `prometheus_snippet.yaml` file
----
+
. Add the label to the <target_namespace>.
+
[role="command"]
----
[root@rhel7-ocp]# oc label namespace <target_namespace> prometheus=monitoring
----
+
. Check to see that the Prometheus targets page is picking up the target endpoints. If the service endpoint is discovered, but Prometheus is reporting a *DOWN* status, you need to make the prometheus-operator project globally accessible.
+
[role="command"]
----
oc adm pod-network make-projects-global prometheus-operator
----

== Deploy Grafana

grafana-datasources.yaml
[source, yaml, linenums, role='code-column hide_tags=comment']
----
include::code/grafana-datasources.yaml[]
----

Regardless of which approach was used to deploy Prometheus on OCP, use Grafana dashboards to visualize the metrics. Use the sample `grafana.yaml` file provided by the OCP GitHub repository to install Grafana. NOTE: Perform the following steps to ensure that Prometheus endpoints are reachable as a data source in Grafana.

. Choose the *same* namespace as Prometheus Operator deployment
+
[role="command"]
----
oc project <your-monitoring-namespace>
----
+
. Go to OpenShift Container Platform web console and Click on Operators > OperatorHub. Search for Grafana Operator and install it. Choose <your-monitoring-namespace> for a specific namespace on the cluster and subscribe.

. Click on Overview and create a Grafana Data Source instance.

. Inside the YAML file, make sure *metadata.namespace* is <your-monitoring-namespace>. Set *spec.datasources.url* to where datasource to the url of the target datasource. For example, if your Prometheus service is *prometheus-operated* on port *9090*, the url should be set to __'http://prometheus-operated:9090'__.

. Click on Overview and create a Grafana instance.

. Inside the YAML file, make sure *metadata.namespace* is <your-monitoring-namespace>. You can define the match expression to select which Dashboards you are interested in under *spec.dashboardLabelSelector.matchExpressions*.

. Click on Overview and create a Grafana Dashboard instance.

. Inside the YAML file, your dashboard can be configured under *spec.json*.

. You can now consume all the application metrics gathered by Prometheus on the Grafana dashboard. Click on Networking > Routes and go to Grafana's location to see your dashboard.

